\documentclass[authoryear, 12pt, a4paper]{elsarticle}

% ------------ packages -------------

\usepackage[utf8]{inputenc}
\usepackage[OT1]{fontenc}
\usepackage{graphicx}
\usepackage[english]{babel}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}

\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{url}
%\usepackage{tikz}
%\usetikzlibrary{shapes.misc,fit}


% ------------ custom defs -------------

\newcommand{\reals}{\mathbb{R}}
\newcommand{\posreals}{\reals_{>0}}
\newcommand{\posrealszero}{\reals_{\ge 0}}
\newcommand{\naturals}{\mathbb{N}}

\newcommand{\mbf}[1]{\mathbf{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}
\renewcommand{\vec}[1]{{\bm#1}}

\newcommand{\uz}{^{(0)}} % upper zero
\newcommand{\un}{^{(n)}} % upper n
\newcommand{\ui}{^{(i)}} % upper i

\newcommand{\ul}[1]{\underline{#1}}
\newcommand{\ol}[1]{\overline{#1}}

\newcommand{\Rsys}{R_\text{sys}}
\newcommand{\lRsys}{\ul{R}_\text{sys}}
\newcommand{\uRsys}{\ol{R}_\text{sys}}

\newcommand{\Fsys}{F_\text{sys}}
\newcommand{\lFsys}{\ul{F}_\text{sys}}
\newcommand{\uFsys}{\ol{F}_\text{sys}}

\def\Tsys{T_\text{sys}}

\newcommand{\E}{\operatorname{E}}
\newcommand{\V}{\operatorname{Var}}

\newcommand{\indic}{\mathbb{I}}

\newcommand{\ber}{\operatorname{Bernoulli}} 
\newcommand{\bin}{\operatorname{Binomial}}
\newcommand{\be}{\operatorname{Beta}} 
\newcommand{\bebin}{\operatorname{Beta-binomial}} 

\def\tmax{t_\text{max}}
\def\tnow{t_\text{now}}
\def\tpnow{t^+_\text{now}}

\input{nydefs.tex}

%\newcommand{\comments}[1]{{\small\color{gray} #1}}

% ------------ options -------------

\allowdisplaybreaks

%\biboptions{longnamesfirst,angle,semicolon}


\journal{IJAR}

\begin{document}

% ------------ frontmatter -------------

\begin{frontmatter}
\title{IJAR Bayesian Nonparametrics Special Issue Manuscript}

\author[ein]{Gero Walter}
\ead{g.m.walter@tue.nl}
\author[oxf]{Louis J.M. Ashlett}
\ead{louis.aslett@stats.ox.ac.uk}
\author[dur]{Frank P.A. Coolen}
\ead{frank.coolen@durham.ac.uk}

\address[ein]{School of Industrial Engineering, Eindhoven University of Technology, Eindhoven, NL}
\address[oxf]{Department of Statistics, University of Oxford, Oxford, UK}
\address[dur]{Department of Mathematical Sciences, Durham University, Durham, UK}

\begin{abstract}
Imprecise Bayesian nonparametric approach to system reliability with multiple types of components,
sets of priors through sets of canonical parameters,
leading to sets of system reliability functions,
reflection of prior-data conflict
\end{abstract}

\begin{keyword}
System reliability \sep
Survival signature \sep
Imprecise probability \sep
Bayesian Nonparametrics \sep
Prior-data conflict
\end{keyword}
\end{frontmatter}


% ------------ manuscript -------------

(author order to be discussed of course)

\section{Introduction}

System with components of $k=1,\ldots,K$ different types.
There are $m_k$ components of type $k$ in the system.
Components of the same type are i.i.d.\ and independent of components of other types.
Arbitrary system layout, i.e.\ any series / parallel combination, $k$ out of $n$ etc.

Based on expert assumptions and data for component failure distribution,
we calculate the system reliability function $\Rsys(t) = P(\Tsys > t)$.

\section{Survival Signature}

Alternative to system signature that allows for
straightforward computation of system reliability
for multiple component types.
It separates the (time-invariant) system structure from the time-dependent failure probabilities of components.

Can be seen as applying the law of total probability by partitioning
according to the number of components of type $k$ functioning at time $t$,
denoted by $C^k_t \in \{0, 1, \ldots, l_k, \ldots, m_k\}$:
\begin{align*}
P(\Tsys > t)
 &= \sum_{l_1=0}^{m_1} \cdots \sum_{l_K=0}^{m_K} P(\Tsys > t \mid C^1_t = l_1,\ldots, C^K_t = l_K)
                                                 P\Big( \bigcap_{k=1}^K \{ C^k_t = l_k\} \Big) \\
 &= \sum_{l_1=0}^{m_1} \cdots \sum_{l_K=0}^{m_K} \Phi(l_1, \ldots, l_K)
                                                 \prod_{k=1}^K P(C^k_t = l_k) \,.
\end{align*}


\section{Nonparametric Bayesian Approach}

The random failure time of component number $i$ of type $k$ is denoted by $T^k_i$, $i = 1, \ldots m_k$.
For its distribution, written in terms of the cdf $F^k(t) = P(T^k_i \le t)$
or in terms of the reliability function $R^k(t) = P(T^k > t) = 1 - F^k(t)$,
we consider a set of time points $t$.

For each time point $t$, the functioning of a single component of type $k$ at time $t$ (functioning: 1, failed: 0)
is Bernoulli distributed with a suitable functioning probability (as, $1-$ failure probability) $p^k_t$,
$\indic(T^k_i > t) \sim \ber(p^k_t)$, $i = 1, \ldots, m_k$.

Then, the number of functioning components out of the $m_k$ components of type $k$
is binomially distributed, $C^k_t = \sum_{i=1}^{m_k} \indic(T^k_i > t) \sim \bin(p^k_t, m_k)$.

The set of functioning probabilities $p^k_t$
corresponding to a choosen set of time points ($t \in {\cal T} = \{t_1, \ldots, \tmax\}$)
defines a discrete failure time distribution for components of type $k$,
$R^k(t) = p^k_{t_j}$, $t \in [t_j, t_{j+1})$.

***or say we don't know for times between time points, or lower and upper bound already here?***

(maybe not relevant for this manuscript, but would it make sense to take Kaplan-Meier estimates for the $p^k_t$'s,
or the NPI bounds for Kaplan-Meier?)

***Right-censored observations maybe in a second step?
Minimal assumption (component can fail immediately after censoring or live forever)
will lead to high imprecision,
assumption of exchangeability with other components at moment of censoring
will be quite complex, maybe too much for this paper,
and could be covered in a second paper with extensive use-case?***

The $p^k_t$'s can be chosen such that they reflect, e.g., a bathtub curve for the corresponding hazard rate.

***Constraint: $p^k_{t_j} \ge p^k_{t_{j+1}}$ must hold (assuming no repair).***

However, directly choosing the $p^k_t$'s is hard,
and fixing values for all $p^k_t$ would furthermore neglect any inherent uncertainty in the particular choice.  
To account for this uncertainty, one can express knowledge on $p^k_t$ through a prior distribution.
A convenient and natural choice is $p^k_t \sim \be(\alpha^k_t, \beta^k_t)$, a conjugate prior,
leading to the posterior being again Beta.

Having observed the lifetime data $\vec{t}^k = (t^k_1, \ldots, t^k_{n_k})$,
at any fixed time $t$ this results in the observation from the Binomial model described above,
$s^k_t = \sum_{i=1}^{n_k} \indic(t^k_i > t)$.
The posterior is then $p^k_t \mid s^k_t \sim \be(\alpha^k_t + s^k_t, \beta^k_t + n_k - s^k_t)$.
The combination of a Binomial observation model with a Beta prior is often called Beta-binomial model.

The posterior predictive distribution for the number of components surviving at time $t$
of the $m_k$ components in the system, based on the lifetime data and the prior information,
is then a so-called Beta-binomial distribution,
$C^k_t \mid s^k_t \sim \bebin(m_k, \alpha^k_t + s^k_t, \beta^k_t + n_k - s^k_t)$.
That is, we have
\begin{align*}
P(C^k_t = l_k \mid s^k_t) &= {m_k \choose l_k} \frac{B(l_k + \alpha^k_t + s^k_t, m_k - l_k + \beta^k_t + n_k - s^k_t)}
                                                    {B(\alpha^k_t + s^k_t, \beta^k_t + n_k - s^k_t)} \,,
\end{align*}
where $B(\cdot, \cdot)$ is the beta function.

The posterior predictive basically averages over $p^k_t \in [0,1]$,
weighted with the posterior on $p^k_t$.

For each component type $k$, we have to choose $2 \times |{\cal T}|$
parameters to specify the prior distribution for the discrete survival function of $T^k_i$,
so in total $2 \times |{\cal T}| \times K$ parameters.

***main contribution of the paper besides the set of priors thing:
guidelines on how to choose the parameters?***

Let us drop the super- and subscript $k$ and $t$ for a while
to discuss the role and interpretation of the parameters $\alpha$ and $\beta$
for each $k$ and $t$.
The Beta distribution is usually parametrized in terms of $\alpha$ and $\beta$ as used above, 
but for our generalization to sets of priors,
it is useful to consider a different parametrization in terms of $\nz$, $\yz$:
\begin{align*}
\nz &= \alpha + \beta &
\yz &= \frac{\alpha}{\alpha + \beta} \,,
\end{align*}
or vice versa, $\alpha = \nz\yz$ and $\beta = \nz(1-\yz)$.
From the properties of the Beta distribution,
we see that $\yz = \E[p]$ is the prior mean for the functioning probability $p$,
and that the higher $\nz$, the more probability weight will be concentrated around that mean,
as $\V(p) = \frac{\yz (1-\yz)}{\nz + 1}$.
Furthermore, $\nz$ can be interpreted as a pseudocount or prior strength,
this will be illustrated through revisiting the posterior
based on observed lifetimes $\vec{t} = (t_1, \ldots, t_{n})$:

$p \mid s$ is Beta distributed with the updated parameters
\begin{align*}
\nn &= \nz + n &
\yn &= \frac{\nz}{\nz + n} \cdot \yz + \frac{n}{\nz + n} \cdot \frac{s}{n}\,,
\end{align*}
so after seeing that $s$ out of $n$ components function (at time $t$),
the posterior mean $\yn$ for $p$ is a weighted average of
the prior mean $\yz$ and $s/n$ (the fraction of function components in the data),
with the weights $\nz$ and $n$, respectively.
We see that $\nz$ plays the same role for the prior mean $\yz$
as the sample size $n$ for the observed mean $s/n$,
thus the notion of pseudocount.
Also, the higher $\nz$, the higher the weight for $\yz$
in the weighted average calculation of $\yn$,
so $\nz$ gives the strength of the prior as compared to the sample size $n$.
%The parameters $\nz$ and $\yz$ have a more intuitive interprtation,

The Beta-binomial distribution in terms of the updated parameters $\nn$ and $\yn$,
now again with indicators $t$ and $k$,
is therefore
\begin{align*}
P(C^k_t = l_k \mid s^k_t) &= {m_k \choose l_k} \frac{B(l_k + \nn_{k,t}\yn_{k,t}, m_k - l_k + \nn_{k,t}(1-\yn_{k,t}))}
                                                    {B(\nn_{k,t}\yn_{k,t}, \nn_{k,t}(1-\yn_{k,t}))} \,.
\end{align*}

The reparametrization enables us to see that in the conjugate setting,
learning from data amounts to averaging between prior and data.
While this allows for the tractability of the model,
it also comes with a serious drawback:
When observed data are very much different from what is assumed in the prior,
this conflict is simply averaged out,
and is not reflected in the posterior or the posterior predictive.
 
***Illustration of such prior-data conflict with $\bebin$ distribution:
different priors updated to same posterior,
or same prior updated to different posteriors with same variance,
show corresponding $C^k_t$ distribution.***



\section{Sets of Priors}

As shown in Walter \& Augustin (2009),
we can have both tractability and meaningful reaction to prior-data conflict
by using sets of priors $\MktZ$ produced by parameter set $\PktZ = [\nktzl, \nktzu] \times [\yktzl, \yktzu]$. 
Then we will have wider intervals for $\Rsys(t)$ in case of prior-data conflict.

Lower and upper bounds for $\Rsys(t)$ by min and max over $\PZ_{1,t}, \ldots, \PZ_{K,t}$.

Monotonicity in $\yz_{k,t}$, so we get
\begin{align*}
\lRsys(t)
 &= \min_{\nz_{1,t},\ldots,\nz_{K,t}} \Rsys(t) \\
 &= \min_{\nz_{1,t},\ldots,\nz_{K,t}} 
    \sum_{l_1=0}^{m_1} \cdots \sum_{l_K=0}^{m_K} \Phi(l_1, \ldots, l_K)
                                                 \prod_{k=1}^K P(C^k_t = l_k \mid s^k_t) \\
 &= \min_{\nz_{1,t},\ldots,\nz_{K,t}} 
    \sum_{l_1=0}^{m_1} \cdots \sum_{l_K=0}^{m_K} \Phi(l_1, \ldots, l_K) \times \\ & \hspace*{12ex}
    \prod_{k=1}^K {m_k \choose l_k} \frac{B(l_k + \nn_{k,t}\ynl_{k,t}, m_k - l_k + \nn_{k,t}(1-\ynl_{k,t}))}
                                         {B(\nn_{k,t}\ynl_{k,t}, \nn_{k,t}(1-\ynl_{k,t}))} \,.
\end{align*}


***do we need to ensure $p^k_{t_j} \ge p^k_{t_{j+1}}$ via $\yzl_{k,t_j} \ge \yzu_{k,t_{j+1}}$?
I would say no, and for relatively dense $t$ grids, neighbouring intervals should be able to overlap after all.
What about requiring $\yzu_{k,t_j} \ge \yzu_{k,t_{j+1}}$ and $\yzl_{k,t_j} \ge \yzl_{k,t_{j+1}}$?
This might not hold for the case when we know, e.g., pretty much what's going on for low $t$
but want to be much more cautious for high $t$.***


\section{Computations}

***publish code as seperate \textbf{R} package, or include in Louis' package \texttt{ReliabilityTheory}
(which contains the function to calculate the survival signature)***


\section{Example}


\section{Conclusions}


\end{document}

